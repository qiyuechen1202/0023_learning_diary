---
title: "Week07"
---

This week introduced a series of machine learning methods applied to remote sensing image classification, and conducted practical exercises using the Google Earth Engine (GEE) platform. Thus, the chapter summarises various machine learning methods (including supervised classification and unsupervised classification), discusses their applications in remote sensing images, and provides my reflection.

# 1. Content Summary: Classification â…  {.unnumbered}

The application of machine learning in remote sensing classification is crucial, due to its efficiency in extracting various features from the imagery datasets. Considering the study at large geographical scales, manual processing is prone to errors and time-consuming. Machine learning effectively addresses the challenges by automating tasks and obtaining highly accurate results, which can improve efficiency and reduce human intervention. Its application has notably accelerated the progress of remote sensing research, particularly in large geographical areas, being utilised for tasks like land cover classification and extracting features such as urban green space and forest fires.

However, it is worth noting that machine learning methods are diverse and demonstrate varied results in their applications. Therefore, understanding these machine learning methods is crucial for our application in remote sensing research. Next, in terms of the methods of image classification, I will review the supervised classification and unsupervised classification methods mentioned in the lecture.

[GISGeograph(2023)](https://gisgeography.com/supervised-unsupervised-classification-arcgis/) summarised the definitions of supervised and unsupervised classification and the differences between them, as shown in Tbale 1.

![Table 1 Comparison between supervised classification and unsupervised classification. Source from [GISGeograph(2023)](https://gisgeography.com/supervised-unsupervised-classification-arcgis/)](source/week07/table1.png)


## 1.1 Unsupervised Classification {.unnumbered}

### 1.1.1 The fundamental steps {.unnumbered}
The fundamental steps for unsupervised classification involve:

1.  Create Cluster
2.  Assign Cluster

### 1.1.2 The Classifiers {.unnumbered}
The common clustering image algorithms are:

1.   **K-mean**

The K-means algorithm is more familiar to us. It assumes that the number of clusters is known prior, and the number of clusters can not be changed as long as the iteration is completed (Sirat, Setiawan and Ramdani, 2018) .


2.   **ISODATA(The Iterative Self-Organizing Data Analysis Technique)**
  

ISODATA is an improved algorithm of K-means, which uses an iterative algorithm to automatically adjust the number of clusters (Arai and Bu.2007). The main work principles of ISODATA are summarised by  (Jensen 2015,. pp.406-407) as follows:
<br/>

-   **Merge Cluster**: Merging clusters occurs when the separation distance in the multispectral feature space falls below a user-specified threshold.
<br/>
<br/>
-   **Split Cluster**:  If the standard deviation of a cluster exceeds a predefined value, and the number of members (pixels) is twice the minimum threshold, the cluster is split into two separate clusters.
<br/>

## 1.2 Supervised Classification {.unnumbered}

### 1.2.1 The processing steps{.unnumbered}
The fundamental steps for supervised classification are as follows: 

1. Class Definition:<br/>
Assemble features which have a property that stores the known class label and properties storing numeric values for the predictors.<br/>
2. Pre-processing:<br/>
Instantiate a classifier. Set its parameters if necessary.<br/>
3. Training:<br/>
Train the classifier using the training data.<br/>
4. Pixel Assignment:<br/>
Classify an image or feature collection.<br/>
5. Accuracy Assessment:<br/>
Estimate classification error with independent validation data.
<br/>

### 1.2.2 The Classifiers{.unnumbered}

The common unsupervised image algorithms are: 

1. **Classification and Regression Tree (CART)** 

CART is a tree-based framework and consists of classification trees and regression trees. It can be used to divide the dataset into subsets  as a tree structure, which can capture different classes (for classification)and predict the value (for regression ). Its application can capture patterns and regularities in data sets to maximise the homogeneity or similarity within each group, making the results more accurate. Gini impurity (for classification) and SME(Squared Mean Error, for regression ) in CART serve as criteria for classifying the subset aiming to minimise impurity or error of resulting subsets. In Figure 1, [RESEDA(no date)](https://blogs.fu-berlin.de/reseda/random-forest/ ) provides an tree-structure example for CART applied for Land classification,which can help me to understand the processing. 

![Figure 1 The land classification process of CART. Source from [RESEDA(no date)](https://blogs.fu-berlin.de/reseda/random-forest/ )](source/week07/CART.png)


::: {.callout-tip collapse="true"}
## The Advantages and Disadvantages of CART

Referring to the similar content of CASA0006, the advantages and disadvantages of CART are summarised as follows:

-   **Advantages**:

    + *Interpretability* : relatively easy to understand (compared to many trees).
    + *Flexibility* : no assumptions of data distribution and no transformations needed.
<br/>

-   **Disadvantages**:

    + *Lack of smoothness* : slight changes in the predicators can have a big impact on the response.
    + *Tendency of overfitting* : meaning that the tree fits well to the training data but is unable to generalise to new data. Thus, it is essential to cut the tree levels to improve the generalisation ability of CART (Lawrence and Wright, 2001)
<br/>
:::

2. **Random Forest (RF)**

RF is an ensemble classifier that consists of many CARTs. Based on the summary of Aziz et al. (2024), the RF workflow (Figure 2) for land classification includes: (1) Random Forests operate on a given dataset with N records(the number of samples) and K outputs (the number of classes);(2) The RF model creates decision trees for each set of samples to produce the output;(3) the final output is determined by assigning greater importance to the majority of votes. 

After the training phase, the RF model becomes adept at making predictions or inferences on new, unseen data. The final result provides distinct labels representing different land types, showcasing its ability to generalise and classify land use with flexibility and accuracy.

![Figure 2 The Workflow of RF. Source from (Bhatnagar, Gill and Ghosh, 2020)](source/week07/Workflow-random-forest-classifier_W640.jpeg)

::: {.callout-tip collapse="true"}
## The Advantages and Disadvantages of RF

Referring to the similar content of CASA0006, the advantages and disadvantages of RF are summarised as follows:

-   **Advantages**:

    + No assumptions on data distribution.
    + Able to model non-linear relationship and feature interactions.
    + Good predictive performance (especially for tabular data).
    + Good generalisation.

-   **Disadvantages**:

    + Low interpretability: not intuitive, although there are some interpretation methods.
<br/>
:::

3. **Other Classifiers**

In addition to CART and RF, the following classifiers were introduced in the lecture. Although their definition and applications are a bit complicated for me, they are very interesting and offer more possibilities to image classification. I hope to deepen my understanding of them in future studies.

-   **Maximum Likelihood**:

-   **Support Vector Machines**:

### 1.2.3 Comparison of CART and RF {.unnumbered}

Based on the code provided in the practical, I also tried to use Landsat 8 data to classify land use in Shenzhen by CART (Figure ) and RF (Figure ). Compared to 

# 2. Application {.unnumbered}

# 3. Reflection {.unnumbered}

# 4. Reference {.unnumbered}
